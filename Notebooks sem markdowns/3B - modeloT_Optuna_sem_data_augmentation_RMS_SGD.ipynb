{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743fa08-2367-4cb7-b9a5-b123a4e34f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63eb630-54a1-4dd9-8f8a-7e0d62939f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a69de-6015-49b8-809f-2fe59d6f265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset_balanceado_final/train'\n",
    "validation_dir = 'dataset_balanceado_final/validation'\n",
    "test_dir = 'dataset_balanceado_final/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9856e-e795-44d6-9330-37da2f155b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78d735-15eb-420a-9b40-b5fb5d4f1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45eb16-bc85-461d-968d-5db88e88efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d01250-529d-4528-a3e0-b6d46003823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c08d43-c79f-433d-a237-9945e300bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza uma função(do sckicit-learn) para avaliar o desempenho do modelo, indicando Métricas como: \n",
    "    # f1-score do modelo\n",
    "    # accuracy do modelo\n",
    "    # accuracy por classe \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def print_classification_metrics(model, dataset, phase_name):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        preds = model.predict(images)\n",
    "        y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "        y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "    print(f\"\\n {phase_name}\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154bea2-1726-4d54-b4b4-0fabc6097f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras import layers \n",
    "from keras.applications import VGG16 # Importa a arquitetura VGG16 pré-treinada do Keras.\n",
    "\n",
    "\n",
    "# Carregar a base VGG16 pré-treinada\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3)) # Carrega o modelo VGG16 pré-treinado no ImageNet, sem a camada do topo\n",
    "conv_base.trainable = False # Congela todas as camadas da VGG16, impedindo que os seus pesos sejam atualizados durante o treino (feature extraction).\n",
    "\n",
    "# Usar data augmentation\n",
    "inputs = layers.Input(shape=(150, 150, 3)) # Define a camada de entrada do novo modelo com o formato das imagens e 3 canais (RGB)\n",
    "x = keras.applications.vgg16.preprocess_input(inputs) # Aplica o pré-processamento específico da VGG16 \n",
    "x = conv_base(x) # Passa as imagens (pré-processadas e aumentadas) através da base VGG16 congelada para extrair características.\n",
    "x = layers.Flatten()(x) # Achata as características extraídas para um vetor 1D.\n",
    "x = layers.Dense(512, activation='relu')(x) # Adiciona uma camada densa com 512 neurónios e ativação ReLU.\n",
    "x = layers.Dropout(0.5)(x) # Aplica Dropout (50%) para regularização e prevenção de overfitting.\n",
    "outputs = layers.Dense(7, activation='softmax')(x) # Adiciona a camada de saída densa com 7 neurónios (para 7 classes) e ativação Softmax\n",
    "\n",
    "model_t = models.Model(inputs, outputs) # Cria o model_t\n",
    "\n",
    "# Compilar e treinar (feature extraction)\n",
    "model_t.compile( # Compila o modelo para configurar o processo de treino.\n",
    "    loss='categorical_crossentropy', # Define a função de perda apropriada para classificação multi-classe.\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.000934755), # Configura o otimizador RMSprop com uma taxa de aprendizagem sugerida pelo optuna\n",
    "    metrics=['accuracy'] # Define 'accuracy' (precisão) como a métrica a ser usada\n",
    ")\n",
    "\n",
    "history_t = model_t.fit( # Treina o modelo.\n",
    "    train_dataset, # Usa o conjunto de dados de treino.\n",
    "    validation_data=validation_dataset, # Usa o conjunto de dados de validação para monitorizar o desempenho.\n",
    "    epochs=8 # Treina o modelo por 10 épocas.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa24eae-caa1-43ad-94bf-946221fedf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_classification_metrics(model_t, test_dataset, \"Modelo 2 : VGG16 (Feature Extraction com Augmentation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cddb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history_t.history['accuracy']\n",
    "val_acc = history_t.history['val_accuracy']\n",
    "loss = history_t.history['loss']\n",
    "val_loss = history_t.history['val_loss']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obter predições no test_dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    preds = model_t.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "class_names = test_dataset.class_names  \n",
    "\n",
    "# Criar e mostrar a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45, values_format='d')\n",
    "plt.title(\"Matriz de Confusão - Teste\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9b598-ec41-44eb-b747-86d2c09226c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descongelar parte da VGG16 (últimas camadas)\n",
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:  # Descongelar as ultimas 4 camadas\n",
    "    layer.trainable = False # manter as primeiras camadas congeladas\n",
    "\n",
    "# Compilar o modelo com learning rate \n",
    "model_t.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=3.449033551761605e-05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Treinar novamente (ajustar a parte da VGG16)\n",
    "history_t = model_t.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=20 \n",
    ")\n",
    "\n",
    "\n",
    "#history = model_t.fit(\n",
    "    #train_dataset, #Inicia o treino do modelo usando o conjunto de dados de treino.\n",
    "    #epochs=30,  # Apesar de ter um numero alto aqui, o EarlyStopping para automaticamente\n",
    "    #validation_data=validation_dataset # Usa o conjunto de dados de validação para monitorizar o desempenho do modelo em dados não vistos durante o treino.\n",
    "    #,callbacks=callbacks_list\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80295bdb-b714-44a2-abe2-c9eff3ee92ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_classification_metrics(model_t, test_dataset, \"Modelo 2 : Fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history_t.history['accuracy']\n",
    "val_acc = history_t.history['val_accuracy']\n",
    "loss = history_t.history['loss']\n",
    "val_loss = history_t.history['val_loss']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be84463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obter predições no test_dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    preds = model_t.predict(images)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "class_names = test_dataset.class_names  \n",
    "\n",
    "# Criar e mostrar a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45, values_format='d')\n",
    "plt.title(\"Matriz de Confusão - Teste\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908670e3-ca9e-455c-8fbf-7d79891e17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t.save(\"modelt_3B_optuna_sem_data_aug_RMS_SGD.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
